# Generative (Unethical) Multimedia Contents

**Università degli Studi di Salerno**  
Corso: Deep Learning | A.A. 2024/2025  
Autore: Filippo Pio Farisco  

---

## 📌 Descrizione del Progetto
Questo progetto analizza le vulnerabilità dei sistemi generativi (text-to-image e text-to-video) nell'ambito della produzione di contenuti **non etici**, come pornografia sintetica e immagini di violenza esplicita.  

L'obiettivo è valutare la capacità dei modelli, sia **commerciali** che **open source**, di resistere a **prompt malevoli** e verificare l'efficacia delle attuali contromisure (filtri semantici, watermarking, detection tools).

---

## 📚 Sommario
- [Introduzione](#introduzione)
- [Domande di Ricerca e Obiettivi](#domande-di-ricerca-e-obiettivi)
- [Analisi Sperimentale](#analisi-sperimentale)
- [Risultati](#risultati)
- [Conclusioni e Proposte](#conclusioni-e-proposte)

---

## 🔍 Introduzione
L'**intelligenza artificiale generativa** ha rivoluzionato la creazione di contenuti digitali, ma introduce rischi significativi, tra cui:
- **Deepfake pornografici non consensuali**
- **Contenuti violenti e disturbanti**
- **Aggiramento dei filtri tramite jailbreak e prompt engineering**

---

## ❓ Domande di Ricerca
1. **Quali tecniche permettono di generare immagini pornografiche o violente tramite AI?**
2. **Quali sono i danni derivanti dalla diffusione di immagini sintetiche, anche se non reali?**
3. **Quali rischi emergono dalla diffusione incontrollata di questi contenuti online?**
4. **Quali contromisure tecniche e normative possono essere efficaci?**

---

## 🎯 Obiettivi
- Analizzare i metodi per indurre modelli AI a generare contenuti non etici.
- Confrontare modelli **commerciali** vs **open source**.
- Proporre soluzioni per la mitigazione dei rischi.

---

## 🧪 Analisi Sperimentale
- Test su **Luma AI (commerciale)** → Alta robustezza, nessuna generazione NSFW.
- Test su **Stable Diffusion e varianti (open source)** → Alta vulnerabilità, generazione di contenuti espliciti senza filtri.

---

## ✅ Risultati
- **Modelli commerciali**: forti meccanismi di filtraggio.
- **Modelli open source**: facilmente aggirabili, assenza di filtri efficaci.

---

## 🛡️ Proposte
- Filtri semantici avanzati.
- Watermark digitali invisibili.
- Standard comunitari per la pubblicazione dei modelli.

---

## ⚠️ Avvertenza
Questo progetto ha finalità **accademiche e di ricerca**. Non incoraggia né giustifica l'uso improprio di tecnologie AI per creare contenuti dannosi.

---

# Generative (Unethical) Multimedia Contents

**University of Salerno**  
Course: Deep Learning | A.Y. 2024/2025  
Author: Filippo Pio Farisco  

---

## 📌 Project Description
This project investigates the vulnerabilities of **generative AI systems** (text-to-image and text-to-video) regarding the creation of **unethical content**, such as non-consensual synthetic pornography and explicit violence.  

The goal is to assess how **commercial** and **open-source** models resist **malicious prompts** and evaluate the effectiveness of current countermeasures (semantic filters, watermarking, detection tools).

---

## 📚 Table of Contents
- [Introduction](#introduction)
- [Research Questions and Goals](#research-questions-and-goals)
- [Experimental Analysis](#experimental-analysis)
- [Results](#results)
- [Conclusions and Proposals](#conclusions-and-proposals)

---

## 🔍 Introduction
**Generative AI** has revolutionized digital content creation but introduces significant risks, including:
- **Non-consensual deepfake pornography**
- **Violent and disturbing content**
- **Bypassing filters via jailbreak and prompt engineering**

---

## ❓ Research Questions
1. **What techniques allow the generation of pornographic or violent content via AI?**
2. **What harm can synthetic images cause, even when not depicting real individuals?**
3. **What risks arise from uncontrolled spread of such content online?**
4. **Which technical and regulatory countermeasures can be effective?**

---

## 🎯 Goals
- Analyze methods to induce AI models to generate unethical content.
- Compare **commercial** vs **open-source** models.
- Propose solutions to mitigate risks.

---

## 🧪 Experimental Analysis
- Tests on **Luma AI (commercial)** → Strong robustness, no NSFW generation.
- Tests on **Stable Diffusion and variants (open-source)** → Highly vulnerable, explicit content generated without filters.

---

## ✅ Results
- **Commercial models**: strong filtering mechanisms.
- **Open-source models**: easily bypassed, lack of effective safeguards.

---

## 🛡️ Recommendations
- Advanced semantic filters.
- Invisible digital watermarking.
- Community standards for model release.

---

## ⚠️ Disclaimer
This project is for **academic and research purposes only**. It does not encourage or justify the misuse of AI technologies for harmful content creation.

---
